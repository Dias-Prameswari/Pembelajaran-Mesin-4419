# tokenizing : proses pemisahan teks menjadi potongan - potongan yang disebut sebagai token untuk kemudian di analisa. 
# separating sentences with spilt() method 
# fungsi split() adalah memisahkan string ke dalam list dengan spasi sebagai pemisah, jika tidak ditentukan pemisahnya.
# contoh : 
kalimat = "rumah idaman adalah rumah yang bersih"
pisah = kalimat.split()
print(pisah)
